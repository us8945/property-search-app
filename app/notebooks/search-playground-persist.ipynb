{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property Search Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting and Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from llama_index.core import Document, ServiceContext\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, get_response_synthesizer\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import os\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.schema import TextNode, NodeRelationship, RelatedNodeInfo\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import ipywidgets as widgets\n",
    "#widgets.IntSlider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_define = [\n",
    "    \"OPENAI_API_KEY\",\n",
    "    \"embeddings_llm\",\n",
    "    \"embeddings_cache_folder\",\n",
    "    \"data_path\",\n",
    "    ]\n",
    "def load_env_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                # Remove whitespace and comments\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    # Split by the first '=' character\n",
    "                    key, value = line.split('=', 1)\n",
    "                    # Remove any surrounding quotes from the value\n",
    "                    value = value.strip().strip('\"').strip(\"'\")\n",
    "                    # Set the environment variable\n",
    "                    if key in variables_to_define:\n",
    "                        os.environ[key.strip()] = value\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {file_path} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "project_path = \"/usr/local/stage3technical/var/sand/property-rag-search\"\n",
    "load_env_file(os.path.join(project_path,'.env'))\n",
    "\n",
    "# Define variables from environment variables\n",
    "embeddings_llm = os.getenv(\"embeddings_llm\")\n",
    "embeddings_cache_folder = os.getenv(\"embeddings_cache_folder\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "data_path = os.getenv(\"data_path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model\n",
    "embedding_model = HuggingFaceEmbedding(model_name=embeddings_llm,\n",
    "                                      cache_folder=embeddings_cache_folder,\n",
    "                                      embed_batch_size=32,\n",
    "                                      )\n",
    "\n",
    "# Generation model\n",
    "generation_llm = OpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    "    api_key=openai_api_key,  # uses OPENAI_API_KEY env var by default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a helpful assistant that can answer questions about the world.\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"What is your LLM model name?\"),\n",
    "]\n",
    "resp = generation_llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping columns for preprocessing\n",
    "key_replacements = {\n",
    "    \"propYear\": \"property year\",\n",
    "    \"propID\": \"property ID\",\n",
    "    \"geoID\": \"geographical ID\",\n",
    "    \"propType\": \"property type\",\n",
    "    \"propSubType\": \"property subtype\",\n",
    "    \"propCategoryCode\": \"property category code\",\n",
    "    \"legalDescription\": \"legal description\",\n",
    "    \"dbaName\": \"doing business as name\",\n",
    "    \"propCreateDate\": \"property creation date\",\n",
    "    \"situsBldgNum\": \"situs building number\",\n",
    "    \"situsStreetPrefix\": \"situs street prefix\",\n",
    "    \"situsStreetName\": \"situs street name\",\n",
    "    \"situsStreetSuffix\": \"situs street suffix\",\n",
    "    \"situsUnit\": \"situs unit\",\n",
    "    \"situsCity\": \"situs city\",\n",
    "    \"situsZip\": \"situs ZIP\",\n",
    "    \"situsConcat\": \"situs concatenated\",\n",
    "    \"situsConcatShort\": \"situs concatenated short\",\n",
    "    \"ownerID\": \"owner ID\",\n",
    "    \"ownerName\": \"owner name\",\n",
    "    \"ownerNameAddtl\": \"owner name additional\",\n",
    "    \"ownerAddrLine1\": \"owner address line 1\",\n",
    "    \"ownerAddrLine2\": \"owner address line 2\",\n",
    "    \"ownerAddrCity\": \"owner address city\",\n",
    "    \"ownerAddrState\": \"owner address state\",\n",
    "    \"ownerAddrZip\": \"owner address ZIP\",\n",
    "    \"ownerAddrCountry\": \"owner address country\",\n",
    "    \"taxAgentID\": \"tax agent ID\",\n",
    "    \"taxAgentName\": \"tax agent name\",\n",
    "    \"imprvYearBuilt\": \"improvement year built\",\n",
    "    \"currValYear\": \"current value year\",\n",
    "    \"currValImprv\": \"current value improvement\",\n",
    "    \"currValLand\": \"current value land\",\n",
    "    \"currValMarket\": \"current value market\",\n",
    "    \"currValAgLoss\": \"current value agriculture loss\",\n",
    "    \"currValAppraised\": \"current value appraised\",\n",
    "}\n",
    "\n",
    "key_for_search = {\n",
    "    \"propID\": \"property ID\",\n",
    "    \"legalDescription\": \"legal description\",\n",
    "    \"dbaName\": \"doing business as name\",\n",
    "    \"situsBldgNum\": \"situs building number\",\n",
    "    \"situsStreetPrefix\": \"situs street prefix\",\n",
    "    \"situsStreetName\": \"situs street name\",\n",
    "    \"situsStreetSuffix\": \"situs street suffix\",\n",
    "    \"situsUnit\": \"situs unit\",\n",
    "    \"situsCity\": \"situs city\",\n",
    "    \"situsZip\": \"situs ZIP\",\n",
    "    \"situsConcat\": \"situs concatenated\",\n",
    "    \"ownerID\": \"owner ID\",\n",
    "    \"ownerName\": \"owner name\",\n",
    "    \"ownerNameAddtl\": \"owner name additional\",\n",
    "}\n",
    "\n",
    "def preprocess_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.rename(columns=key_replacements, inplace=True)\n",
    "    filtered_df = df[list(key_for_search.values())]\n",
    "    return df, filtered_df\n",
    "\n",
    "def convert_to_documents(df):\n",
    "    return [row.to_dict() for _, row in df.iterrows()]\n",
    "\n",
    "def get_documents_facts(document: dict):\n",
    "    facts = \"\"\n",
    "    for key, value in document.items():\n",
    "        facts += f\"{key}: {value}\\n\"\n",
    "    return facts\n",
    "\n",
    "\n",
    "def create_node_representation(input_dict):\n",
    "    # Extract relevant fields\n",
    "    legal_description = input_dict.get(\"legal description\", \"N/A\")\n",
    "    owner_id = input_dict.get(\"owner ID\", \"N/A\")\n",
    "    owner_name = input_dict.get(\"owner name\", \"N/A\")\n",
    "    owner_name_additional = input_dict.get(\"owner name additional\", \"N/A\")\n",
    "    property_id = input_dict.get(\"property ID\", \"N/A\")\n",
    "    situs_concatenated = input_dict.get(\"situs concatenated\", \"N/A\")\n",
    "    situs_city = input_dict.get(\"situs city\", \"N/A\")\n",
    "    situs_zip = input_dict.get(\"situs ZIP\", \"N/A\")\n",
    "    dba = input_dict.get(\"doing business as name\", \"N/A\")\n",
    "    \n",
    "    # Combine owner names if additional owner exists\n",
    "    if (owner_name_additional in [\"N/A\", \"nan\"] or pd.isna(owner_name_additional)):\n",
    "        owner_names = owner_name\n",
    "    else:\n",
    "        owner_names = f\"{owner_name} and {owner_name_additional}\"\n",
    "\n",
    "    # Construct the natural language description\n",
    "    value = (\n",
    "        f\"This property, located at {situs_concatenated}, is legally described as \"\n",
    "        f\"'{legal_description}'. The property ID is {property_id}. \"\n",
    "        f\"It is owned by {owner_names}, with an owner ID of {owner_id}. \"\n",
    "    )\n",
    "    if not(dba == \"N/A\" or pd.isna(dba)):\n",
    "        value += f\"The property is also known as {dba}.\"\n",
    "\n",
    "    # Construct the output dictionary\n",
    "    output_node = {\n",
    "        \"key\": f\"Property Information - {situs_concatenated}\",\n",
    "        \"value\": value,\n",
    "        \"metadata\": {\n",
    "            \"property_id\": property_id,\n",
    "            \"situs_city\": situs_city,\n",
    "            \"situs_zip\": situs_zip,\n",
    "            \"owner_name\": owner_names,\n",
    "            \"legal_description\": legal_description\n",
    "        }\n",
    "    }\n",
    "    return output_node\n",
    "\n",
    "\n",
    "def get_nodes(input_file_path):\n",
    "    df, filtered_df = preprocess_csv(input_file_path)\n",
    "    documents = convert_to_documents(filtered_df)\n",
    "    full_nodes = []\n",
    "    owner_nodes = []\n",
    "    all_nodes = []\n",
    "    node_id = 0\n",
    "    for document in documents:\n",
    "        doc_node = create_node_representation(document)\n",
    "        node_text = f\"{doc_node['key']}. {doc_node['value']}\"\n",
    "        node_full = TextNode(text=node_text, \n",
    "                             id_=str(node_id),\n",
    "                             metadata=doc_node[\"metadata\"])\n",
    "        node_owner = TextNode(text=doc_node[\"metadata\"][\"owner_name\"],\n",
    "                              id_=str(node_id)+\"_owner\",\n",
    "                              metadata={\n",
    "                                  \"owner_name\":doc_node[\"metadata\"][\"owner_name\"],\n",
    "                                  \"legal_description\":doc_node[\"metadata\"][\"legal_description\"],\n",
    "                              }\n",
    "                              )\n",
    "        node_full.relationships[NodeRelationship.CHILD] = [RelatedNodeInfo(node_id=node_owner.node_id)]\n",
    "        node_owner.relationships[NodeRelationship.PARENT] = RelatedNodeInfo(node_id=node_full.node_id)\n",
    "        node_id += 1        \n",
    "        full_nodes.append(node_full)\n",
    "        owner_nodes.append(node_owner)\n",
    "        all_nodes.append(node_full)\n",
    "        all_nodes.append(node_owner)\n",
    "\n",
    "    return full_nodes, owner_nodes, all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_file_path = os.path.join(data_path, \"Collin_CAD_Appraisal_Data_2024_20241208_75024.csv\")\n",
    "# df, filtered_df = preprocess_csv(property_file_path)\n",
    "full_nodes, owner_nodes, all_nodes = get_nodes(property_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes\n",
    "leaf_nodes = get_leaf_nodes(all_nodes)\n",
    "root_nodes = get_root_nodes(all_nodes)\n",
    "print(f\"Number of leaf nodes: {len(leaf_nodes)}\")\n",
    "print(f\"Number of root nodes: {len(root_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import MetadataMode\n",
    "# This is what is visible to the embeddings model\n",
    "print(\"*\"*50)\n",
    "print(\"Visible to Embeddings model\")\n",
    "print(full_nodes[0].get_content(metadata_mode=MetadataMode.EMBED))\n",
    "\n",
    "# This is what is visible to the LLM\n",
    "print(\"*\"*50)\n",
    "print(\"Visible to LLM\")\n",
    "print(full_nodes[0].get_content(metadata_mode=MetadataMode.LLM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_nodes[10])\n",
    "print(owner_nodes[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_nodes[0].relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nodes[0].relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Document Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define storage context\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(all_nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# owner_nodes are defined as leaf nodes\n",
    "owner_index = VectorStoreIndex(nodes=owner_nodes,\n",
    "                               embed_model=embedding_model,\n",
    "                               index_name=\"owner_index\",\n",
    "                               show_progress=True,\n",
    "                               insert_batch_size=10000,\n",
    "                               storage_context=storage_context,\n",
    "                              )\n",
    "print(\"Owner index created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "\n",
    "base_retriever = owner_index.as_retriever(similarity_top_k=20)\n",
    "auto_merge_retriever = AutoMergingRetriever(base_retriever, storage_context, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_str = \"What were some lessons learned from red-teaming?\"\n",
    "# query_str = \"Can you tell me about the key concepts for safety finetuning\"\n",
    "query_str = (\n",
    "    \"What properties are owned by 'Jacob'\"\n",
    ")\n",
    "\n",
    "nodes = auto_merge_retriever.retrieve(query_str)\n",
    "print(f\"Number of retrieved nodes: {len(nodes)}\")\n",
    "for node in nodes:\n",
    "    print(node)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = (\n",
    "    \"What properties are owned by 'Smith'\"\n",
    ")\n",
    "\n",
    "nodes = auto_merge_retriever.retrieve(query_str)\n",
    "print(f\"Number of retrieved nodes: {len(nodes)}\")\n",
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_merge_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever=auto_merge_retriever,\n",
    "                                              llm=generation_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [\n",
    "        (\"What properties are owned by 'Smith'\"),\n",
    "        (\"What properties are owned by 'Smeeth'\"),\n",
    "        (\"What properties are owned by 'Smithes'\"),\n",
    "    ]\n",
    "\n",
    "for query_str in query_list:\n",
    "    response = query_engine.query(query_str)\n",
    "    print(f\"Query: {query_str}\")\n",
    "    print(str(response))\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [(\"List all owners with name resembling 'Jacob'\"),]\n",
    "\n",
    "for query_str in query_list:\n",
    "    response = query_engine.query(query_str)\n",
    "    print(f\"Query: {query_str}\")\n",
    "    print(str(response))\n",
    "    print(\"*\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collin-12-20-24",
   "language": "python",
   "name": "collin-12-20-24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
