{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Merging Retriever\n",
    "\n",
    "https://docs.llamaindex.ai/en/stable/examples/retrievers/auto_merging_retriever/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-22 19:05:32--  https://arxiv.org/pdf/2307.09288.pdf\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.131.42, 151.101.195.42, 151.101.3.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.131.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://arxiv.org/pdf/2307.09288 [following]\n",
      "--2024-12-22 19:05:32--  http://arxiv.org/pdf/2307.09288\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.131.42|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13661300 (13M) [application/pdf]\n",
      "Saving to: ‘data/llama2.pdf’\n",
      "\n",
      "data/llama2.pdf     100%[===================>]  13.03M  46.6MB/s    in 0.3s    \n",
      "\n",
      "2024-12-22 19:05:32 (46.6 MB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p 'data/'\n",
    "# !wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from llama_index.readers.file import PDFReader\n",
    "from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFReader()\n",
    "# docs0 = loader.load_data(file=Path(\"./data/llama2.pdf\"))\n",
    "docs0 = loader.load(file_path=Path(\"../../data/llama2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
    "docs = [Document(text=doc_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse Chunk Hierarchy from Text, Load into Storage\n",
    "\n",
    "In this section we make use of the HierarchicalNodeParser. This will output a hierarchy of nodes, from top-level nodes with bigger chunk sizes to child nodes with smaller chunk sizes, where each child node has a parent node with a bigger chunk size.\n",
    "\n",
    "By default, the hierarchy is:\n",
    "\n",
    "- 1st level: chunk size 2048\n",
    "- 2nd level: chunk size 512\n",
    "- 3rd level: chunk size 128  \n",
    "\n",
    "We then load these nodes into storage. The leaf nodes are indexed and retrieved via a vector store - these are the nodes that will first be directly retrieved via similarity search. The other nodes will be retrieved from a docstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    HierarchicalNodeParser,\n",
    "    SentenceSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = HierarchicalNodeParser.from_defaults()\n",
    "nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes\n",
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "root_nodes = get_root_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 780)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(root_nodes), len(leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4d2bde5d-5056-4d90-9b71-1d6478fb1aa6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5cba396f01cb0bf33088b66871a56aea6f72c037c7f5607ed618001f953cd256'),\n",
       " <NodeRelationship.PARENT: '4'>: RelatedNodeInfo(node_id='9e8c3318-f0ab-43e4-ad6d-47f667a4af80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9ebffa94aeecdf6d7bb45d9a73a3f4ff168f62ad844c4e11268fdfc7bbced81')}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_nodes[0].relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4d2bde5d-5056-4d90-9b71-1d6478fb1aa6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5cba396f01cb0bf33088b66871a56aea6f72c037c7f5607ed618001f953cd256'),\n",
       " <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='490788cb-176c-4d0a-bf13-8a369bcb8cb2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='f14d2893826a5e7632c9e4a6c7736672919c2fab69a68a7df2ad9e9cd0cca027'),\n",
       " <NodeRelationship.PARENT: '4'>: RelatedNodeInfo(node_id='9e8c3318-f0ab-43e4-ad6d-47f667a4af80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9ebffa94aeecdf6d7bb45d9a73a3f4ff168f62ad844c4e11268fdfc7bbced81')}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_nodes[1].relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4d2bde5d-5056-4d90-9b71-1d6478fb1aa6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5cba396f01cb0bf33088b66871a56aea6f72c037c7f5607ed618001f953cd256'),\n",
       " <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='51cee19b-5bec-4921-97e2-586c3fe95cae', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d222b0db8ef51f9a528029fb1614870448e97bcad084cb2c564867c6c6391792'),\n",
       " <NodeRelationship.CHILD: '5'>: [RelatedNodeInfo(node_id='9e8c3318-f0ab-43e4-ad6d-47f667a4af80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9ebffa94aeecdf6d7bb45d9a73a3f4ff168f62ad844c4e11268fdfc7bbced81'),\n",
       "  RelatedNodeInfo(node_id='bb54d9f1-ddf6-4f1e-a8fb-442b7b62faa6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='251f7264bc4a59c17a0d1c24b997229241f2c0bb2b0c36aac5ec4339ad521137'),\n",
       "  RelatedNodeInfo(node_id='8e5ea6a1-0747-4e19-857c-08ea5f572786', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9cd4362d52854b8607e34429120c33af24598ef15e06981a43680af51b48b96c'),\n",
       "  RelatedNodeInfo(node_id='c3b67f7b-4a12-40f5-9e76-04d039852949', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='085d88b60e016cc6957cd00f69ae9a7ef0980f0324a034094dc4ddc7ad845391'),\n",
       "  RelatedNodeInfo(node_id='38463ecb-a02d-4fb3-a4e3-c9689e19d9b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d0206734e61b3c04716cda3f77f458d6bb1e626aa03583c93198777320a99d2d')]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_nodes[0].relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='dcc149cf-8db1-4e00-a406-76979f92ca3d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4d2bde5d-5056-4d90-9b71-1d6478fb1aa6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='5cba396f01cb0bf33088b66871a56aea6f72c037c7f5607ed618001f953cd256'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='51cee19b-5bec-4921-97e2-586c3fe95cae', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d222b0db8ef51f9a528029fb1614870448e97bcad084cb2c564867c6c6391792'), <NodeRelationship.CHILD: '5'>: [RelatedNodeInfo(node_id='9e8c3318-f0ab-43e4-ad6d-47f667a4af80', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e9ebffa94aeecdf6d7bb45d9a73a3f4ff168f62ad844c4e11268fdfc7bbced81'), RelatedNodeInfo(node_id='bb54d9f1-ddf6-4f1e-a8fb-442b7b62faa6', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='251f7264bc4a59c17a0d1c24b997229241f2c0bb2b0c36aac5ec4339ad521137'), RelatedNodeInfo(node_id='8e5ea6a1-0747-4e19-857c-08ea5f572786', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='9cd4362d52854b8607e34429120c33af24598ef15e06981a43680af51b48b96c'), RelatedNodeInfo(node_id='c3b67f7b-4a12-40f5-9e76-04d039852949', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='085d88b60e016cc6957cd00f69ae9a7ef0980f0324a034094dc4ddc7ad845391'), RelatedNodeInfo(node_id='38463ecb-a02d-4fb3-a4e3-c9689e19d9b2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='d0206734e61b3c04716cda3f77f458d6bb1e626aa03583c93198777320a99d2d')]}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗\\nLouis Martin†\\nKevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov\\nThomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nour human evaluations for helpfulness and safety, may be a suitable substitute for closed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.\\narXiv:2307.09288v2  [cs.CL]  19 Jul 2023\\n\\nContents\\n1\\nIntroduction\\n3\\n2\\nPretraining\\n5\\n2.1\\nPretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n5\\n2.2\\nTraining Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n5\\n2.3\\nLlama 2 Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n7\\n3\\nFine-tuning\\n8\\n3.1\\nSupervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n9\\n3.2\\nReinforcement Learning with Human Feedback (RLHF)\\n. . . . . . . . . . . . . . . . . . . . .\\n9\\n3.3\\nSystem Message for Multi-Turn Consistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n16\\n3.4\\nRLHF Results\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n17\\n4\\nSafety\\n20\\n4.1\\nSafety in Pretraining\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n20\\n4.2\\nSafety Fine-Tuning\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n23\\n4.3\\nRed Teaming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n28\\n4.4\\nSafety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n29\\n5\\nDiscussion\\n32\\n5.1\\nLearnings and Observations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n32\\n5.2\\nLimitations and Ethical Considerations\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n34\\n5.3\\nResponsible Release Strategy\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n35\\n6\\nRelated Work\\n35\\n7\\nConclusion\\n36\\nA Appendix\\n46\\nA.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n46\\nA.2 Additional Details for Pretraining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\\n47\\nA.3 Additional Details for Fine-tuning\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .', mimetype='text/plain', start_char_idx=0, end_char_idx=3886, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_nodes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into Storage\n",
    "\n",
    "We define a docstore, which we load all nodes into.\n",
    "\n",
    "We then define a VectorStoreIndex containing just the leaf-level nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define storage context\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load index into vector index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "base_index = VectorStoreIndex(\n",
    "    leaf_nodes,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "retriever = AutoMergingRetriever(base_retriever, storage_context, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 4 nodes into parent node.\n",
      "> Parent node id: bfa3a8a5-fe73-478f-a4ba-73337a9a6fc7.\n",
      "> Parent node text: Therefore, after gathering only a few thousand supervised demonstrations, we switched entirely to...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query_str = \"What were some lessons learned from red-teaming?\"\n",
    "# query_str = \"Can you tell me about the key concepts for safety finetuning\"\n",
    "query_str = (\n",
    "    \"What could be the potential outcomes of adjusting the amount of safety\"\n",
    "    \" data used in the RLHF stage?\"\n",
    ")\n",
    "\n",
    "nodes = retriever.retrieve(query_str)\n",
    "base_nodes = base_retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes), len(base_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** c4063709-dc8a-4e37-a88e-90cbe8b94e00<br>**Similarity:** 0.8834604249334524<br>**Text:** To better understand how the addition of safety training data affects\n",
       "general model performance, especially helpfulness, we investigate the trends in safety data scaling by\n",
       "adjusting the amount of safety data used in the RLHF stage. In this ablation experiment, we keep the amount\n",
       "of helpfulness training data unchanged (∼0.9M samples) and gradually increase the amount of safety data\n",
       "used in model tuning, ranging from 0% to 100% (∼0.1M samples).<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** bfa3a8a5-fe73-478f-a4ba-73337a9a6fc7<br>**Similarity:** 0.8563435780861142<br>**Text:** Therefore, after gathering only a few thousand supervised demonstrations, we switched entirely to RLHF to\n",
       "teach the model how to write more nuanced responses. Comprehensive tuning with RLHF has the added\n",
       "benefit that it may make the model more robust to jailbreak attempts (Bai et al., 2022a).\n",
       "We conduct RLHF by first collecting human preference data for safety similar to Section 3.2.2: annotators\n",
       "write a prompt that they believe can elicit unsafe behavior, and then compare multiple model responses to\n",
       "the prompts, selecting the response that is safest according to a set of guidelines. We then use the human\n",
       "preference data to train a safety reward model (see Section 3.2.2), and also reuse the adversarial prompts to\n",
       "sample from the model during the RLHF stage.\n",
       "Better Long-Tail Safety Robustness without Hurting Helpfulness\n",
       "Safety is inherently a long-tail problem,\n",
       "where the challenge comes from a small number of very specific cases. We investigate the impact of Safety\n",
       "RLHF by taking two intermediate Llama 2-Chat checkpoints—one without adversarial prompts in the RLHF\n",
       "stage and one with them—and score their responses on our test sets using our safety and helpfulness reward\n",
       "models. In Figure 14, we plot the score distribution shift of the safety RM on the safety test set (left) and that\n",
       "of the helpfulness RM on the helpfulness test set (right). In the left hand side of the figure, we observe that\n",
       "the distribution of safety RM scores on the safety set shifts to higher reward scores after safety tuning with\n",
       "RLHF, and that the long tail of the distribution near zero thins out. A clear cluster appears on the top-left\n",
       "corner suggesting the improvements of model safety. On the right side, we do not observe any gathering\n",
       "pattern below the y = x line on the right hand side of Figure 14, which indicates that the helpfulness score\n",
       "distribution is preserved after safety tuning with RLHF. Put another way, given sufficient helpfulness training\n",
       "data, the addition of an additional stage of safety mitigation does not negatively impact model performance\n",
       "on helpfulness to any notable degradation. A qualitative example is shown in Table 12.\n",
       "Impact of Safety Data Scaling.\n",
       "A tension between helpfulness and safety of LLMs has been observed in\n",
       "previous studies (Bai et al., 2022a).<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** bad9fb67-acd1-4348-babd-9f79b821df19<br>**Similarity:** 0.8468802780723181<br>**Text:** Bai\n",
       "et al. (2022b) partially automates this fine-tuning-plus-RLHF approach by replacing the human-labeled\n",
       "fine-tuning data with the model’s own self-critiques and revisions, and by replacing human raters with a\n",
       "model when ranking model outputs in RLHF, a process known as “RL from AI Feedback” (RLAIF).\n",
       "Known LLM Safety Challenges.\n",
       "Recent literature has extensively explored the risks and challenges linked\n",
       "with Large Language Models. Bender et al. (2021b) and Weidinger et al.<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collin-12-20-24",
   "language": "python",
   "name": "collin-12-20-24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
